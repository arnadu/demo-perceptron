{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459dae4b-816b-4147-9604-81d3af96b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33810181 -0.33810181]\n",
      " [-0.51517717  0.51517717]\n",
      " [ 0.41493877 -0.41493877]\n",
      " [-0.54353703  0.54353703]\n",
      " [ 0.39578836 -0.39578836]]\n",
      "layer1_o [[0.         0.83386834 0.         0.71137402]\n",
      " [0.         0.         0.         0.03205647]\n",
      " [0.         0.01854553 0.         0.40249548]\n",
      " [0.         1.19688386 0.         0.        ]\n",
      " [0.         1.27451733 0.         0.31603917]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.960732484246908,\n",
       " array([[0.33810181, 0.66189819],\n",
       "        [0.48482283, 0.51517717],\n",
       "        [0.41493877, 0.58506123],\n",
       "        [0.45646297, 0.54353703],\n",
       "        [0.39578836, 0.60421164]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy_loss(y, pred):\n",
    "    l = -np.log(pred)*y  #calculate y*log(p) for each category of each sample of the batch\n",
    "    individual_losses = np.sum(l, -1)  #sum over categories\n",
    "    batch_loss = np.sum(individual_losses) #sum over samples\n",
    "    return batch_loss, individual_losses\n",
    "\n",
    "def softmax(z):\n",
    "    \n",
    "    #input\n",
    "    # z a S*C matrix rows = samples, columns same dimension as number of categories\n",
    "    m = np.max(z)   #normalize to avoid large numbers \n",
    "    e = np.exp(z - m)\n",
    "    return e / e.sum(axis=1, keepdims=True) #[:,None]\n",
    "\n",
    "def relu(v):\n",
    "    return np.where(v>0., v, 0.)\n",
    "\n",
    "\n",
    "def init(seed=1):\n",
    "    \n",
    "    global b1, w1, b2, w2\n",
    "    global g_b1, g_w1, g_b2, g_w2\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    w1 = 2*np.random.random((input_dim , layer1_dim)) - 1\n",
    "    b1 = 2*np.random.random(layer1_dim) - 1\n",
    "    w2 = 2*np.random.random((layer1_dim, output_dim)) - 1\n",
    "    b2 = 2*np.random.random(output_dim) - 1\n",
    "\n",
    "    g_b2 = np.zeros_like(b2)\n",
    "    g_w2 = np.zeros_like(w2)\n",
    "    g_b1 = np.zeros_like(b1)\n",
    "    g_w1 = np.zeros_like(w1)\n",
    "\n",
    "def forward(X):\n",
    "\n",
    "    '''\n",
    "    X is expected to be shape=(S,I) \n",
    "    S: is the number of samples in a batch\n",
    "    I: the number of input values for each sample\n",
    "    '''\n",
    "\n",
    "    global b1, w1, b2, w2\n",
    "    global g_b1, g_w1, g_b2, g_w2\n",
    "\n",
    "    global layer1_v, layer1_o\n",
    "    global layer2_v, layer2_o\n",
    "    \n",
    "    #forward \n",
    "    #matmul will return a matrix of size SxL1 where L1 is size of layer1\n",
    "    layer1_v = np.matmul(X,w1) + b1\n",
    "    layer1_o = relu(layer1_v)  #shape=(S,L1)\n",
    "\n",
    "    layer2_v = np.matmul(layer1_o,w2) + b2  #shape=(S,C) where C is size of output=number of categories\n",
    "    layer2_o = softmax(layer2_v)  #shape=(S,C)\n",
    "    \n",
    "    return layer2_o\n",
    "\n",
    "def backrop_weights(X,Y,alpha):\n",
    "\n",
    "    global b1, w1, b2, w2\n",
    "    global g_b1, g_w1, g_b2, g_w2\n",
    "\n",
    "    global layer1_v, layer1_o\n",
    "    global layer2_v, layer2_o\n",
    "    \n",
    "    g_b2 = np.zeros_like(b2)\n",
    "    g_w2 = np.zeros_like(w2)\n",
    "    g_b1 = np.zeros_like(b1)\n",
    "    g_w1 = np.zeros_like(w1)\n",
    "    \n",
    "    g_loss_softmax = -(Y-layer2_o)  #shape=S,C\n",
    "    print(g_loss_softmax)\n",
    "\n",
    "    g_b2 = np.sum(g_loss_softmax, axis=0) #shape C; sum(axis=0) is sum over samples\n",
    "\n",
    "    g_w2 = np.einsum(\"ij,ik\",layer1_o, g_loss_softmax)\n",
    "    print(\"layer1_o\", layer1_o)\n",
    "    \n",
    "    dRelu = np.where(layer1_v>0., 1., 0.)  #shape=S,L1\n",
    "\n",
    "    g_b1 += np.einsum(\"il,kl,ik->k\",g_loss_softmax,w2,dRelu)\n",
    "\n",
    "    g_w1 += np.einsum(\"il,kl,ik,ij->jk\",g_loss_softmax,w2,dRelu,X)\n",
    "    \n",
    "    b2 -= alpha * g_b2 / X.shape[0] #average over number of samples\n",
    "    w2 -= alpha * g_w2 / X.shape[0]\n",
    "    b1 -= alpha * g_b1 / X.shape[0]\n",
    "    w1 -= alpha * g_w1 / X.shape[0]\n",
    "    \n",
    "    return g_b1, g_w1, g_b2, g_w2\n",
    "\n",
    "def train(X, Y, num_periods, alpha=0.1):\n",
    "    \n",
    "    global b1, w1, b2, w2\n",
    "    global g_b1, g_w1, g_b2, g_w2\n",
    "    \n",
    "    for p in range(num_periods):\n",
    "        \n",
    "        batch_X = X #[0:1,:]\n",
    "        batch_Y = Y #[0:1,:]\n",
    "        #print(\"batch_X:\",batch_X)\n",
    "        \n",
    "        pred = forward(batch_X)\n",
    "        loss, _ = cross_entropy_loss(batch_Y, pred)  #loss scalar, _ is vector of size S, total loss for entire batch, loss for each sample of batch\n",
    "        #print(p,loss)\n",
    "\n",
    "        '''\n",
    "        eps=0.001\n",
    "        fg_b2 = np.zeros_like(b2)\n",
    "        for i in range(b2.shape[0]):\n",
    "            b2[i] += eps\n",
    "            loss1, _ = cross_entropy_loss(batch_Y, forward(batch_X))\n",
    "            fg_b2[i] = (loss1-loss)/eps\n",
    "            b2[i] -= eps\n",
    "        forward(X)\n",
    "\n",
    "        eps=0.001\n",
    "        fg_b1 = np.zeros_like(b1)\n",
    "        for i in range(b1.shape[0]):\n",
    "            b1[i] += eps\n",
    "            loss1, _ = cross_entropy_loss(batch_Y, forward(batch_X))\n",
    "            fg_b1[i] = (loss1-loss)/eps\n",
    "            b1[i] -= eps\n",
    "        forward(X)\n",
    "\n",
    "        eps=0.001\n",
    "        fg_w2 = np.zeros_like(w2)\n",
    "        for i in range(w2.shape[0]):\n",
    "            for j in range(w2.shape[1]):\n",
    "                w2[i][j] += eps\n",
    "                loss1, _ = cross_entropy_loss(batch_Y, forward(batch_X))\n",
    "                fg_w2[i][j] = (loss1-loss)/eps\n",
    "                w2[i][j] -= eps\n",
    "        forward(X)\n",
    "        \n",
    "        eps=0.001\n",
    "        fg_w1 = np.zeros_like(w1)\n",
    "        for i in range(w1.shape[0]):\n",
    "            for j in range(w1.shape[1]):\n",
    "                w1[i][j] += eps\n",
    "                loss1, _ = cross_entropy_loss(batch_Y, forward(batch_X))\n",
    "                fg_w1[i][j] = (loss1-loss)/eps\n",
    "                w1[i][j] -= eps\n",
    "        forward(batch_X)\n",
    "       ''' \n",
    "        \n",
    "        backrop_weights(batch_X, batch_Y,alpha)\n",
    "#        print(fg_b1, g_b1)\n",
    "#        print(fg_b2, g_b2)\n",
    "#        print(fg_w1, g_w1)\n",
    "#        print(fg_w2,g_w2)\n",
    "\n",
    "    \n",
    "    return loss, pred\n",
    "\n",
    "input_dim = 3\n",
    "layer1_dim = 4\n",
    "output_dim = 2  #2 classes\n",
    "\n",
    "\n",
    "X_train = np.array([[0,0,1], \n",
    "                    [0,1,0],\n",
    "                    [0,1,1],\n",
    "                    [1,0,0],\n",
    "                    [1,0,1]])\n",
    "\n",
    "Y_train = np.array([[0,1],\n",
    "                    [1,0],\n",
    "                    [0,1],\n",
    "                    [1,0],\n",
    "                    [0,1]])\n",
    "\n",
    "init()\n",
    "train(X_train, Y_train, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310b3398-0c7c-4ae7-b88a-95021b3dfb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "input_dim = 3\n",
    "layer1_dim = 5\n",
    "output_dim = 2  #2 classes\n",
    "\n",
    "S=100 #number of samples\n",
    "\n",
    "X1 = 2*np.random.rand(S,3) - 1\n",
    "\n",
    "Y1 = np.zeros((S,2))\n",
    "Y1[:,0] = np.where(X1[:,0]+X1[:,1]+X1[:,2]>0,1,0)\n",
    "Y1[:,1] = np.where(X1[:,0]+X1[:,1]+X1[:,2]>0,0,1)\n",
    "\n",
    "\n",
    "\n",
    "#plt.scatter(X1[:,0],X1[:,1],c=color,alpha=0.5)\n",
    "init(1)\n",
    "train(X1,Y1,100, alpha=0.1)\n",
    "\n",
    "pred = forward(X1)\n",
    "\n",
    "color = np.where(Y1[:,0]>0,\"red\",\"blue\")\n",
    "marker = np.where(pred[:,0]>0.5,\"o\",\"s\")\n",
    "\n",
    "fig = plt.figure()\n",
    "#ax = fig.add_subplot(projection='3d')\n",
    "ax = fig.add_subplot()\n",
    "for i in range(X1.shape[0]):\n",
    "    ax.scatter(X1[i,0],X1[i,1],c=color[i],marker=marker[i],alpha=0.5)\n",
    "    ax.scatter(X1[i,0],X1[i,1],c=color[i],marker=marker[i],alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8646db35-cd3b-4779-afac-8f875e1a031f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
